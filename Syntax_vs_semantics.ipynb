{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9326fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde6fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample document\n",
    "docs = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The do lay on the mat.\",\n",
    "    \"The ct and dog played together.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f208053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==== Bag of Words ====\n",
      "   and  cat  ct  do  dog  lay  mat  on  played  sat  the  together\n",
      "0    0    1   0   0    0    0    1   1       0    1    2         0\n",
      "1    0    0   0   1    0    1    1   1       0    0    2         0\n",
      "2    1    0   1   0    1    0    0   0       1    0    1         1\n"
     ]
    }
   ],
   "source": [
    "# ==== Bag of Words ====\n",
    "print(\"\\n ==== Bag of Words ====\")\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow_matrix = bow_vectorizer.fit_transform(docs)\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns = bow_vectorizer.get_feature_names_out())\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f9a87ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==== TF-IDF ====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>cat</th>\n",
       "      <th>ct</th>\n",
       "      <th>do</th>\n",
       "      <th>dog</th>\n",
       "      <th>lay</th>\n",
       "      <th>mat</th>\n",
       "      <th>on</th>\n",
       "      <th>played</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "      <th>together</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.468699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356457</td>\n",
       "      <td>0.356457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.468699</td>\n",
       "      <td>0.553642</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.468699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.468699</td>\n",
       "      <td>0.356457</td>\n",
       "      <td>0.356457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553642</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.432385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255374</td>\n",
       "      <td>0.432385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and       cat        ct  ...       sat       the  together\n",
       "0  0.000000  0.468699  0.000000  ...  0.468699  0.553642  0.000000\n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.553642  0.000000\n",
       "2  0.432385  0.000000  0.432385  ...  0.000000  0.255374  0.432385\n",
       "\n",
       "[3 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== TF-IDF ====\n",
    "print(\"\\n ==== TF-IDF ====\")\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(docs)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bca25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==== Word2Vec (spaCy averaged vectors ) ====\n",
      "Requirement already satisfied: spacy in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (0.15.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (2.2.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (2.11.5)\n",
      "Requirement already satisfied: jinja2 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (80.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<8.2,>=8.0.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: wrapt in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "     ---------------------------------------- 0.0/400.7 MB ? eta -:--:--\n",
      "     - ------------------------------------ 19.4/400.7 MB 95.6 MB/s eta 0:00:04\n",
      "     -- ----------------------------------- 28.0/400.7 MB 67.5 MB/s eta 0:00:06\n",
      "     --- ---------------------------------- 35.1/400.7 MB 55.0 MB/s eta 0:00:07\n",
      "     --- ---------------------------------- 41.4/400.7 MB 48.3 MB/s eta 0:00:08\n",
      "     ---- --------------------------------- 47.4/400.7 MB 44.2 MB/s eta 0:00:08\n",
      "     ---- --------------------------------- 51.4/400.7 MB 40.1 MB/s eta 0:00:09\n",
      "     ----- -------------------------------- 54.8/400.7 MB 36.3 MB/s eta 0:00:10\n",
      "     ----- -------------------------------- 59.0/400.7 MB 34.2 MB/s eta 0:00:10\n",
      "     ------ ------------------------------- 63.7/400.7 MB 32.9 MB/s eta 0:00:11\n",
      "     ------ ------------------------------- 68.2/400.7 MB 31.7 MB/s eta 0:00:11\n",
      "     ------ ------------------------------- 72.4/400.7 MB 30.5 MB/s eta 0:00:11\n",
      "     ------- ------------------------------ 76.3/400.7 MB 29.5 MB/s eta 0:00:11\n",
      "     ------- ------------------------------ 78.9/400.7 MB 28.1 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 81.5/400.7 MB 26.9 MB/s eta 0:00:12\n",
      "     -------- ----------------------------- 84.9/400.7 MB 26.2 MB/s eta 0:00:13\n",
      "     -------- ----------------------------- 89.7/400.7 MB 25.9 MB/s eta 0:00:13\n",
      "     -------- ----------------------------- 93.8/400.7 MB 25.6 MB/s eta 0:00:12\n",
      "     --------- ---------------------------- 97.5/400.7 MB 25.0 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 101.7/400.7 MB 24.8 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 107.0/400.7 MB 24.8 MB/s eta 0:00:12\n",
      "     ---------- -------------------------- 112.5/400.7 MB 24.8 MB/s eta 0:00:12\n",
      "     ---------- -------------------------- 116.4/400.7 MB 24.5 MB/s eta 0:00:12\n",
      "     ----------- ------------------------- 121.6/400.7 MB 24.5 MB/s eta 0:00:12\n",
      "     ----------- ------------------------- 127.7/400.7 MB 24.6 MB/s eta 0:00:12\n",
      "     ------------ ------------------------ 134.5/400.7 MB 24.9 MB/s eta 0:00:11\n",
      "     ------------ ------------------------ 138.4/400.7 MB 24.7 MB/s eta 0:00:11\n",
      "     ------------- ----------------------- 143.7/400.7 MB 24.6 MB/s eta 0:00:11\n",
      "     ------------- ----------------------- 146.8/400.7 MB 24.3 MB/s eta 0:00:11\n",
      "     -------------- ---------------------- 152.0/400.7 MB 24.3 MB/s eta 0:00:11\n",
      "     -------------- ---------------------- 156.8/400.7 MB 24.2 MB/s eta 0:00:11\n",
      "     -------------- ---------------------- 162.0/400.7 MB 24.3 MB/s eta 0:00:10\n",
      "     --------------- --------------------- 168.6/400.7 MB 24.4 MB/s eta 0:00:10\n",
      "     ---------------- -------------------- 173.8/400.7 MB 24.4 MB/s eta 0:00:10\n",
      "     ---------------- -------------------- 178.0/400.7 MB 24.3 MB/s eta 0:00:10\n",
      "     ---------------- -------------------- 183.2/400.7 MB 24.3 MB/s eta 0:00:09\n",
      "     ----------------- ------------------- 187.7/400.7 MB 24.2 MB/s eta 0:00:09\n",
      "     ----------------- ------------------- 191.9/400.7 MB 24.1 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 195.8/400.7 MB 23.9 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 199.5/400.7 MB 23.7 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 203.7/400.7 MB 23.7 MB/s eta 0:00:09\n",
      "     ------------------- ----------------- 208.7/400.7 MB 23.7 MB/s eta 0:00:09\n",
      "     ------------------- ----------------- 214.7/400.7 MB 23.8 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 219.9/400.7 MB 23.8 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 224.4/400.7 MB 23.7 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 227.5/400.7 MB 23.5 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 231.5/400.7 MB 23.4 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 234.1/400.7 MB 23.2 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 237.5/400.7 MB 23.0 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 242.0/400.7 MB 22.9 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 246.9/400.7 MB 22.9 MB/s eta 0:00:07\n",
      "     ----------------------- ------------- 250.6/400.7 MB 22.8 MB/s eta 0:00:07\n",
      "     ----------------------- ------------- 254.5/400.7 MB 22.8 MB/s eta 0:00:07\n",
      "     ----------------------- ------------- 257.7/400.7 MB 22.6 MB/s eta 0:00:07\n",
      "     ------------------------ ------------ 261.4/400.7 MB 22.5 MB/s eta 0:00:07\n",
      "     ------------------------ ------------ 266.1/400.7 MB 22.2 MB/s eta 0:00:07\n",
      "     ------------------------- ----------- 270.8/400.7 MB 21.9 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 274.5/400.7 MB 21.6 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 277.9/400.7 MB 21.2 MB/s eta 0:00:06\n",
      "     -------------------------- ---------- 282.1/400.7 MB 21.0 MB/s eta 0:00:06\n",
      "     -------------------------- ---------- 286.0/400.7 MB 20.8 MB/s eta 0:00:06\n",
      "     -------------------------- ---------- 290.5/400.7 MB 20.6 MB/s eta 0:00:06\n",
      "     --------------------------- --------- 294.9/400.7 MB 20.5 MB/s eta 0:00:06\n",
      "     --------------------------- --------- 299.6/400.7 MB 20.4 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 303.8/400.7 MB 20.3 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 309.1/400.7 MB 20.2 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 315.1/400.7 MB 20.4 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 319.3/400.7 MB 20.5 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 323.7/400.7 MB 20.4 MB/s eta 0:00:04\n",
      "     ------------------------------ ------ 329.3/400.7 MB 20.5 MB/s eta 0:00:04\n",
      "     ------------------------------- ----- 336.1/400.7 MB 20.7 MB/s eta 0:00:04\n",
      "     ------------------------------- ----- 341.3/400.7 MB 21.0 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 347.6/400.7 MB 21.4 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 354.9/400.7 MB 21.6 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 361.8/400.7 MB 21.9 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 366.0/400.7 MB 21.8 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 370.1/400.7 MB 21.8 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 375.1/400.7 MB 21.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 380.4/400.7 MB 21.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 383.5/400.7 MB 21.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 389.0/400.7 MB 21.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  395.6/400.7 MB 21.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- 400.7/400.7 MB 18.8 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# ==== Word2Vec using spaCy ====\n",
    "print(\" ==== Word2Vec (spaCy averaged vectors ) ====\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5953828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc):\n",
    "    return nlp(doc).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da32bdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Word2Vec matrix :  (3, 300)\n",
      "Word2 Vec Document Similarity Matrix : \n",
      "          Doc 1     Doc 2     Doc 3\n",
      "Doc 1  1.000000  0.922870  0.783612\n",
      "Doc 2  0.922870  1.000000  0.753228\n",
      "Doc 3  0.783612  0.753228  1.000000\n"
     ]
    }
   ],
   "source": [
    "word2vec_matrix = np.array([document_vector(doc) for doc in docs])\n",
    "print(\"Shape of Word2Vec matrix : \", word2vec_matrix.shape)\n",
    "\n",
    "# ==== Document Similarity using Word2Vec ====\n",
    "print(\"Word2 Vec Document Similarity Matrix : \")\n",
    "print(pd.DataFrame(cosine_similarity(word2vec_matrix), \n",
    "                   columns=[f'Doc {i+1}' for i in range(len(docs))],\n",
    "                   index=[f'Doc {i+1}' for i in range(len(docs))]\n",
    "                   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef41bc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Word Similarity : 'cat' vs 'dog' ====\n",
      "BoW Similarity :  0.0000\n"
     ]
    }
   ],
   "source": [
    "# ==== Word Similarity 'cat' vs 'dog' ====\n",
    "\n",
    "print(\"==== Word Similarity : 'cat' vs 'dog' ====\")\n",
    "\n",
    "# ------ Using BOW ------\n",
    "bow_vocab = bow_vectorizer.vocabulary_\n",
    "cat_bow = np.zeros(len(bow_vocab))\n",
    "dog_bow = np.zeros(len(bow_vocab))\n",
    "if 'cat' in bow_vocab:\n",
    "    cat_bow[bow_vocab['cat']] = 1\n",
    "if 'dog' in bow_vocab:\n",
    "    dog_bow[bow_vocab['dog']] = 1\n",
    "sim_bow = cosine_similarity([cat_bow], [dog_bow])[0][0]    \n",
    "print(f\"BoW Similarity :  {sim_bow:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "168d2dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Similarity : 0.0000\n"
     ]
    }
   ],
   "source": [
    "# ===== Using TF-IDF =====\n",
    "\n",
    "tfidf_vocab = tfidf_vectorizer.vocabulary_\n",
    "cat_tfidf = np.zeros(len(tfidf_vocab))\n",
    "dog_tfidf = np.zeros(len(tfidf_vocab))\n",
    "if 'cat' in tfidf_vocab:\n",
    "    cat_tfidf[tfidf_vocab['cat']] = 1\n",
    "if 'dog' in tfidf_vocab:\n",
    "    dog_tfidf[tfidf_vocab['dog']] = 1    \n",
    "sim_tfidf = cosine_similarity([cat_tfidf], [dog_tfidf])[0][0]\n",
    "print(f\"TF-IDF Similarity : {sim_tfidf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5c6eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Similarity : 0.8017\n"
     ]
    }
   ],
   "source": [
    "# ------ Using Word2Vec ------\n",
    "cat_vec = nlp(\"cat\").vector\n",
    "dog_vec = nlp(\"dog\").vector\n",
    "sim_word2vec = cosine_similarity([cat_vec], [dog_vec])[0][0]\n",
    "print(f\"Word2Vec Similarity : {sim_word2vec:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
