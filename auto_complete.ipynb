{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff7a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: torch in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from torch) (80.8.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\workspace\\nlp_cv\\.venv\\lib\\site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee754966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'With the evolution of AI there is a vernacular to define \"The Mind\", although this term is misleading given that some individuals are known as\\'medieval thinkers\\'.\\nAnd the best way for AI to understand itself is in \"solving mysteries through its data\". As AI becomes progressively better you will have far better answers for what questions need to be answered.\\nWe can call things on the idea of neural information processing in any area based on our experience without any further data about other areas on the way. Now let\\'s consider a case where our information cannot tell the whole truth.\\nIt is called brain. An information processing unit represents this type of \"brain\". Our best tools are not the tools that provide real cognitive training to understand our data, either – so as to improve brain level. The machine makes changes. If we choose to listen carefully as that does not increase our response curve, and our brain will not be equipped to comprehend the truth a bit better, this may become even harder. That machine often just wants you to get rid of your bias which can be changed or that can make sense in less than 10 months time. When that happens it should help you find other parts of the mental puzzle instead of worrying. (Just because there are two can make you better at these areas) Brain training doesn'}]\n",
      "Auto-complete:  With the evolution of AI there is a vernacular to define \"The Mind\", although this term is misleading given that some individuals are known as'medieval thinkers'.\n",
      "And the best way for AI to understand itself is in \"solving mysteries through its data\". As AI becomes progressively better you will have far better answers for what questions need to be answered.\n",
      "We can call things on the idea of neural information processing in any area based on our experience without any further data about other areas on the way. Now let's consider a case where our information cannot tell the whole truth.\n",
      "It is called brain. An information processing unit represents this type of \"brain\". Our best tools are not the tools that provide real cognitive training to understand our data, either – so as to improve brain level. The machine makes changes. If we choose to listen carefully as that does not increase our response curve, and our brain will not be equipped to comprehend the truth a bit better, this may become even harder. That machine often just wants you to get rid of your bias which can be changed or that can make sense in less than 10 months time. When that happens it should help you find other parts of the mental puzzle instead of worrying. (Just because there are two can make you better at these areas) Brain training doesn\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a text generation model (GPT-2)\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# Function to get auto-completion suggestions\n",
    "def autocomplete(prompt, max_length=100):           # max_lenth: Result = How many words including after our incomplete sentence?\n",
    "    result = generator(prompt, max_length=max_length, num_return_sequences=1, temperature=1.5, top_k=50, pad_token_id=50256)\n",
    "    # temperature = 0.7 .... Controls randomness (0.7 is low, 1.5 will mean more creative responses)\n",
    "    # top_k = 50 .... Consider only top 50 words for each step\n",
    "    # pad_token_id = 50256 .... Stop generating and do not generate indefinitely (50256 = EOS)\n",
    "    print(result)\n",
    "    return result[0]['generated_text']\n",
    "    # result = List of generated outputs\n",
    "    # Take only the first and only sentence\n",
    "\n",
    "# Example usage \n",
    "# prompt = \"The difference between Human Intelligence and AI \"\n",
    "# print(\"Auto-complete: \", autocomplete(prompt))\n",
    "\n",
    "# prompt = \"Machine Learning is \"\n",
    "# print(\"Auto-complete : \", autocomplete(prompt))\n",
    "\n",
    "# prompt = \"The future of AI is \"\n",
    "# print(\"Auto-complete: \", autocomplete(prompt))\n",
    "\n",
    "prompt = \"With the evolution of AI there is a \"\n",
    "print(\"Auto-complete: \", autocomplete(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aaf876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
